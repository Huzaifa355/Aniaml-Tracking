{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40accbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 703 files belonging to 3 classes.\n",
      "Found 176 files belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 783ms/step - accuracy: 0.5030 - loss: 1.3378 - val_accuracy: 0.9375 - val_loss: 0.3162\n",
      "Epoch 2/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 474ms/step - accuracy: 0.8988 - loss: 0.3391 - val_accuracy: 0.9773 - val_loss: 0.1280\n",
      "Epoch 3/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9363 - loss: 0.2025 - val_accuracy: 0.9830 - val_loss: 0.0856\n",
      "Epoch 4/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 438ms/step - accuracy: 0.9652 - loss: 0.1354 - val_accuracy: 0.9830 - val_loss: 0.0700\n",
      "Epoch 5/5\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9623 - loss: 0.1103 - val_accuracy: 0.9886 - val_loss: 0.0557\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 949ms/step - accuracy: 0.8937 - loss: 0.3242 - val_accuracy: 0.9886 - val_loss: 0.0465\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9667 - loss: 0.1223 - val_accuracy: 0.9830 - val_loss: 0.0445\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 636ms/step - accuracy: 0.9837 - loss: 0.0766 - val_accuracy: 0.9773 - val_loss: 0.0467\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 533ms/step - accuracy: 0.9857 - loss: 0.0574 - val_accuracy: 0.9773 - val_loss: 0.0502\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 559ms/step - accuracy: 0.9827 - loss: 0.0604 - val_accuracy: 0.9773 - val_loss: 0.0418\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 520ms/step - accuracy: 0.9764 - loss: 0.0631 - val_accuracy: 0.9886 - val_loss: 0.0282\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 523ms/step - accuracy: 0.9884 - loss: 0.0593 - val_accuracy: 0.9943 - val_loss: 0.0214\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 524ms/step - accuracy: 0.9825 - loss: 0.0463 - val_accuracy: 0.9943 - val_loss: 0.0165\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 523ms/step - accuracy: 0.9818 - loss: 0.0405 - val_accuracy: 0.9943 - val_loss: 0.0133\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 527ms/step - accuracy: 0.9917 - loss: 0.0337 - val_accuracy: 0.9943 - val_loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done — MobileNetV1 training finished.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "# ——— your folders ———\n",
    "TRAIN_DIR = r'D:\\iot project\\train'\n",
    "VAL_DIR   = r'D:\\iot project\\val'\n",
    "IMG_SIZE  = (224, 224)\n",
    "BATCH     = 32\n",
    "NUM_CLASSES = 3  # cow,goat,hen\n",
    "\n",
    "# 1. Datasets\n",
    "train_ds = image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    label_mode='int',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ").map(lambda x, y: (mobilenet_preprocess(x), y)) \\\n",
    " .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    label_mode='int',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False\n",
    ").map(lambda x, y: (mobilenet_preprocess(x), y)) \\\n",
    " .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 2. Build MobileNetV1-based model\n",
    "base = tf.keras.applications.MobileNet(\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    alpha=0.25,\n",
    "    weights='imagenet',     # transfer learn from ImageNet\n",
    "    include_top=False\n",
    ")\n",
    "base.trainable = False     # freeze for initial training\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(*IMG_SIZE, 3)),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "\n",
    "# 3. Compile & train head\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# 4. Unfreeze some of the base for fine-tuning\n",
    "base.trainable = True\n",
    "for layer in base.layers[:50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# 5. Optional: Combine histories or save model\n",
    "model.save('mobilenetv1_finetuned.h5')\n",
    "print(\"✅ Done — MobileNetV1 training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416b9172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\white\\AppData\\Local\\Temp\\tmp1g8wmp53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\white\\AppData\\Local\\Temp\\tmp1g8wmp53\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\white\\AppData\\Local\\Temp\\tmp1g8wmp53'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1167228486096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228499344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228499728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228499536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228498384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228501072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228500688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228498000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228501648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228498192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167228500112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338685648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338684688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338685456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338684496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338687184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338687568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338687952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338687760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338684880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338689104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338689488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338689872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338689680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338686032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338691024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338691408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338691792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338691600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338686800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338692944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338693328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338693712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338693520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338688720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338694864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338695248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338695632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338695440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338690640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338696784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338697168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338697552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338697360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338692560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338698704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338699088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338699472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338699280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338694480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338700624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338696400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338848528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338700240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338698320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338850064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338850448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338850832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338850640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338848720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338851984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338852368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338852752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338852560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338849296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338853904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338854288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338854672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338854480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338849680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338855824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338856208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338856592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338856400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338851600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338857744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338858128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338858512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338858320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338853520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338859664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338860048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338860432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338860240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338855440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338861584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338861968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338862352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338862160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338857360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338863504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338863120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338861200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338864080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338859280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167338862736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339078864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339077904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339078672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339077712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339080400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339080784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339081168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339080976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339078096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339082320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339082704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339083088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339082896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339079248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339084240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339084624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339085008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339084816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339080016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339086160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339086544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339086928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339086736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339081936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339088080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339088464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339088848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339088656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339083856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339090000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339090384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339090768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339090576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339085776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339091920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339092304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339092688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339092496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339087696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339093840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167339091536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167337193744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1167337195472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantization complete, saved mobilenetv1_quant.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model(r'D:\\iot project\\mobilenetv1_finetuned.h5', compile=False)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def rep_data_gen():\n",
    "    for _ in range(100):\n",
    "        # random float in [0,1], matching your model's float32 input\n",
    "        dummy = np.random.random_sample((1,224,224,3)).astype(np.float32)\n",
    "        yield [dummy]\n",
    "\n",
    "converter.representative_dataset = rep_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Keep the I/O as float32 so it matches your model signature\n",
    "# (the weights & activations will still be quantized to int8 internally)\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open('mobilenetv1_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ Quantization complete, saved mobilenetv1_quant.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176 files belonging to 3 classes.\n",
      "→ Model input details: {'name': 'serving_default_input_layer_1:0', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([ -1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "→ Model expects dtype: <class 'numpy.float32'> shape: [  1 224 224   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# ——— EDIT THESE PATHS IF NEEDED ———\n",
    "TFLITE_MODEL_PATH = r'D:\\iot project\\mobilenetv1_quant.tflite'\n",
    "VAL_DIR            = r'D:\\iot project\\val'     # cow/,goat/Hen\n",
    "BATCH_SIZE         = 32\n",
    "IMG_SIZE           = (224, 224)\n",
    "\n",
    "# 1. Load validation dataset (values in [0,255], dtype uint8)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 2. Load TFLite interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "input_details  = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(\"→ Model input details:\", input_details)\n",
    "print(\"→ Model expects dtype:\", input_details['dtype'],\n",
    "      \"shape:\", input_details['shape'])\n",
    "\n",
    "# 3. Evaluate\n",
    "total, correct = 0, 0\n",
    "\n",
    "for batch_images, batch_labels in val_ds:\n",
    "    # Convert to numpy for feeding the interpreter\n",
    "    imgs = batch_images.numpy()           # shape (batch,128,128,3), uint8\n",
    "\n",
    "    # 3a. Preprocess depending on expected input dtype\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        # Model wants uint8 [0..255]\n",
    "        batch_input = imgs.astype(np.uint8)\n",
    "\n",
    "    elif input_details['dtype'] == np.float32:\n",
    "        # Model wants float32 in [0..1]\n",
    "        batch_input = (imgs / 255.0).astype(np.float32)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported input dtype: {input_details['dtype']}\")\n",
    "\n",
    "    # 3b. Run per-image inference\n",
    "    for img, true_label in zip(batch_input, batch_labels.numpy()):\n",
    "        # Expand dims to match [1, h, w, c]\n",
    "        interpreter.set_tensor(input_details['index'], np.expand_dims(img, 0))\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details['index'])[0]  # e.g. shape [3]\n",
    "        pred_label = np.argmax(output)\n",
    "\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "# 4. Report\n",
    "acc = 100 * correct / total if total else 0\n",
    "print(f'Validation accuracy: {acc:.2f}%  ({correct}/{total})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
