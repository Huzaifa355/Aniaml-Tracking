{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40accbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 files belonging to 2 classes.\n",
      "Found 80 files belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.6446 - loss: 0.7128 - val_accuracy: 0.9000 - val_loss: 0.2578\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 472ms/step - accuracy: 0.8892 - loss: 0.2675 - val_accuracy: 0.9500 - val_loss: 0.1323\n",
      "Epoch 3/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 499ms/step - accuracy: 0.9529 - loss: 0.1317 - val_accuracy: 0.9875 - val_loss: 0.0803\n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.9827 - loss: 0.0860 - val_accuracy: 0.9875 - val_loss: 0.0622\n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 428ms/step - accuracy: 0.9971 - loss: 0.0602 - val_accuracy: 0.9875 - val_loss: 0.0410\n",
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 870ms/step - accuracy: 0.9322 - loss: 0.1617 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 601ms/step - accuracy: 0.9918 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 799ms/step - accuracy: 1.0000 - loss: 0.0371 - val_accuracy: 0.9875 - val_loss: 0.0323\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.9957 - loss: 0.0245 - val_accuracy: 0.9875 - val_loss: 0.0336\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 604ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 608ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0183\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 572ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 653ms/step - accuracy: 0.9994 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0151\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 588ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done — MobileNetV1 training finished.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "# ——— your folders ———\n",
    "TRAIN_DIR = r'D:\\iot project\\train'\n",
    "VAL_DIR   = r'D:\\iot project\\val'\n",
    "IMG_SIZE  = (224, 224)\n",
    "BATCH     = 32\n",
    "NUM_CLASSES = 2  # cow,hen\n",
    "\n",
    "# 1. Datasets\n",
    "train_ds = image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    label_mode='int',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ").map(lambda x, y: (mobilenet_preprocess(x), y)) \\\n",
    " .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    label_mode='int',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=False\n",
    ").map(lambda x, y: (mobilenet_preprocess(x), y)) \\\n",
    " .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 2. Build MobileNetV1-based model\n",
    "base = tf.keras.applications.MobileNet(\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    alpha=0.25,\n",
    "    weights='imagenet',     # transfer learn from ImageNet\n",
    "    include_top=False\n",
    ")\n",
    "base.trainable = False     # freeze for initial training\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(*IMG_SIZE, 3)),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "\n",
    "# 3. Compile & train head\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# 4. Unfreeze some of the base for fine-tuning\n",
    "base.trainable = True\n",
    "for layer in base.layers[:50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# 5. Optional: Combine histories or save model\n",
    "model.save('mobilenetv1_finetuned.h5')\n",
    "print(\"✅ Done — MobileNetV1 training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416b9172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\white\\AppData\\Local\\Temp\\tmp4i7vo20j\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\white\\AppData\\Local\\Temp\\tmp4i7vo20j\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\white\\AppData\\Local\\Temp\\tmp4i7vo20j'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_3')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2488831474576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831473808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831475344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831474768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831474384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831474192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876843664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876844240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831473424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876843088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876845392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876845776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876846160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876845968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876843280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876847312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876847696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876848080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876847888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876843856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876849232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876849616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876850000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876849808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876845008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876851152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876851536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876851920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876851728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876846928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876853072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876853456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876853840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876853648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876848848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876854992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876855376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876855760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876855568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876850768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876856912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876857296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876857680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876857488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876852688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876858832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876843472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876859216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876859024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488876856528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877041040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877041424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877041808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877041616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877039888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877042960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877043344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877043728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877043536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877044880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877045264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877045648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877045456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877046800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877047184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877047568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877047376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877042576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877048720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877049104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877049488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877049296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877044496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877050640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877051024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877051408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877051216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877046416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877052560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877052944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877053328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877053136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877048336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877054480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877054864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877055632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877055056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877050256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877053712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877236304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877237456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877054096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877237264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877238608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877238992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877239376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877239184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877237072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877240528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877240912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877241296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877241104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877236496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877242448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877242832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877243216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877243024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877238224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877244368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877244752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877245136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877244944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877240144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877246288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877246672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877247056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877246864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877242064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877248208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488825168144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831474000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488877248784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488831472464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488693392592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130635344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130635152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130640912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130636496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130646096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130647632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130649168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130648400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130641488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130648784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130645712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130644176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2488130640336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantization complete, saved mobilenetv1_quant.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model(r'D:\\iot project\\mobilenetv1_finetuned.h5', compile=False)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "def rep_data_gen():\n",
    "    for _ in range(100):\n",
    "        # random float in [0,1], matching your model's float32 input\n",
    "        dummy = np.random.random_sample((1,224,224,3)).astype(np.float32)\n",
    "        yield [dummy]\n",
    "\n",
    "converter.representative_dataset = rep_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Keep the I/O as float32 so it matches your model signature\n",
    "# (the weights & activations will still be quantized to int8 internally)\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "with open('mobilenetv1_quant.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ Quantization complete, saved mobilenetv1_quant.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84e7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 files belonging to 2 classes.\n",
      "→ Model input details: {'name': 'serving_default_input_layer_3:0', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([ -1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "→ Model expects dtype: <class 'numpy.float32'> shape: [  1 224 224   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\white\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 98.75%  (79/80)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# ——— EDIT THESE PATHS IF NEEDED ———\n",
    "TFLITE_MODEL_PATH = r'D:\\iot project\\mobilenetv1_quant.tflite'\n",
    "VAL_DIR            = r'D:\\iot project\\val'     # cow/,goat/Hen\n",
    "BATCH_SIZE         = 32\n",
    "IMG_SIZE           = (224, 224)\n",
    "\n",
    "# 1. Load validation dataset (values in [0,255], dtype uint8)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 2. Load TFLite interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "input_details  = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "print(\"→ Model input details:\", input_details)\n",
    "print(\"→ Model expects dtype:\", input_details['dtype'],\n",
    "      \"shape:\", input_details['shape'])\n",
    "\n",
    "# 3. Evaluate\n",
    "total, correct = 0, 0\n",
    "\n",
    "for batch_images, batch_labels in val_ds:\n",
    "    # Convert to numpy for feeding the interpreter\n",
    "    imgs = batch_images.numpy()           # shape (batch,128,128,3), uint8\n",
    "\n",
    "    # 3a. Preprocess depending on expected input dtype\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        # Model wants uint8 [0..255]\n",
    "        batch_input = imgs.astype(np.uint8)\n",
    "\n",
    "    elif input_details['dtype'] == np.float32:\n",
    "        # Model wants float32 in [0..1]\n",
    "        batch_input = (imgs / 255.0).astype(np.float32)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported input dtype: {input_details['dtype']}\")\n",
    "\n",
    "    # 3b. Run per-image inference\n",
    "    for img, true_label in zip(batch_input, batch_labels.numpy()):\n",
    "        # Expand dims to match [1, h, w, c]\n",
    "        interpreter.set_tensor(input_details['index'], np.expand_dims(img, 0))\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details['index'])[0]  # e.g. shape [3]\n",
    "        pred_label = np.argmax(output)\n",
    "\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "# 4. Report\n",
    "acc = 100 * correct / total if total else 0\n",
    "print(f'Validation accuracy: {acc:.2f}%  ({correct}/{total})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
